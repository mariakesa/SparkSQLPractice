{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ID=8951354, Date='12/31/12 23:15', LocationDescription='STREET', Arrest=False, Domestic=False, Beat=623, District='6', CommunityArea='69', Year=2012, Latitude=41.75628399, Longitude=-87.62164472)\n",
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- LocationDescription: string (nullable = true)\n",
      " |-- Arrest: boolean (nullable = true)\n",
      " |-- Domestic: boolean (nullable = true)\n",
      " |-- Beat: integer (nullable = true)\n",
      " |-- District: string (nullable = true)\n",
      " |-- CommunityArea: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      "\n",
      "None\n",
      "['ID', 'Date', 'LocationDescription', 'Arrest', 'Domestic', 'Beat', 'District', 'CommunityArea', 'Year', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"HousingPrices\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "schema=StructType([StructField('ID',IntegerType(),False),StructField('ProductID',IntegerType(),False),StructField('Cost',FloatType(),False)])\n",
    "\n",
    "base = spark.read.csv(\"file:///home/maria/Documents/SparkSQLPractice/MITAnalyticsEdge/mvtWeek1.csv\",inferSchema=True,header=True)\n",
    "print(base.head())\n",
    "print(base.printSchema())\n",
    "print(base.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ID: a unique identifier for each observation\n",
    "Date: the date the crime occurred\n",
    "LocationDescription: the location where the crime occurred\n",
    "Arrest: whether or not an arrest was made for the crime (TRUE if an arrest was made, and FALSE if an arrest was not made)\n",
    "Domestic: whether or not the crime was a domestic crime, meaning that it was committed against a family member (TRUE if it was domestic, and FALSE if it was not domestic)\n",
    "Beat: the area, or \"beat\" in which the crime occurred. This is the smallest regional division defined by the Chicago police department.\n",
    "District: the police district in which the crime occured. Each district is composed of many beats, and are defined by the Chicago Police Department.\n",
    "CommunityArea: the community area in which the crime occurred. Since the 1920s, Chicago has been divided into what are called \"community areas\", of which there are now 77. The community areas were devised in an attempt to create socially homogeneous regions.\n",
    "Year: the year in which the crime occurred.\n",
    "Latitude: the latitude of the location at which the crime occurred.\n",
    "Longitude: the longitude of the location at which the crime occurred.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| row_n|\n",
      "+------+\n",
      "|191641|\n",
      "+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base.createOrReplaceTempView(\"crimes\")\n",
    "#Number of rows in data\n",
    "qur = spark.sql(\"SELECT COUNT(*) as row_n FROM crimes\")\n",
    "print(qur.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "#Number of columns in data\n",
    "print(len(base.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| max_id|\n",
      "+-------+\n",
      "|9181151|\n",
      "+-------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Max ID\n",
    "qur_max=spark.sql(\"SELECT MAX(ID) as max_id FROM crimes\")\n",
    "print(qur_max.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min_beat|\n",
      "+--------+\n",
      "|     111|\n",
      "+--------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Min Beat\n",
    "qur_min=spark.sql(\"SELECT MIN(Beat) as min_beat FROM crimes\")\n",
    "print(qur_min.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|nr_arrests|\n",
      "+----------+\n",
      "|     15536|\n",
      "+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Nr of crimes with arrest\n",
    "qur_arr=spark.sql(\"SELECT COUNT(*) as nr_arrests FROM crimes WHERE Arrest=TRUE\")\n",
    "print(qur_arr.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|nr_arrests|\n",
      "+----------+\n",
      "|      2308|\n",
      "+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#How many observations have a LocationDescription value of ALLEY?\n",
    "qur_all=spark.sql(\"SELECT COUNT(*) as nr_arrests FROM crimes WHERE LocationDescription='ALLEY'\")\n",
    "print(qur_all.show())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
